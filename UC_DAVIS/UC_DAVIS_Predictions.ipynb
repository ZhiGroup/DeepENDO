{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download checkpoints from \n",
    "https://drive.google.com/drive/folders/16IXv-w6xpHhEQiSNjRSI8S5wS4QDjGKE?usp=sharing\n",
    "\n",
    "2. The checkpoints for T1 and T2 are seperate\n",
    "\n",
    "3. We use ukbiobank preprocessed images. Link to download ukbiobank preprocessing documentation and code is \n",
    "https://git.fmrib.ox.ac.uk/falmagro/UK_biobank_pipeline_v_1\n",
    "https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf\n",
    "\n",
    "\n",
    "4. The only custom imports are model_128 and dataset\n",
    "\n",
    "5. Packages needed are listed in requirments if imports fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from monai import transforms\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from model_128 import *\n",
    "from dataset import *\n",
    "\n",
    "# from dataset import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import nibabel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"List of names of MRI\"\n",
    "T1_files= list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "checkpoint = torch.load(T1_ckpt, map_location=device)\n",
    "model = model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_ds = aedataset(\n",
    "    datafile=T1_files, modality= \"T1_unbiased_linear\"\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    T1_ds, batch_size=16, pin_memory=True, num_workers=32, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(\n",
    "             reduction=\"none\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_val = []\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        img, mask = data\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        recon, lin1 = model(img)\n",
    "        loss = loss_fn(img, recon)\n",
    "        loss1 = loss.squeeze(1) * mask\n",
    "        loss2 = loss1.sum()\n",
    "        loss3 = loss2 / mask.sum()\n",
    "        losses_val.append(loss3.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean validation loss\")\n",
    "print(np.mean(losses_val))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82114572b5f995edcfb2c41ea8a6603276c1890a8e11c6cbf3e354bd23c27cae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
